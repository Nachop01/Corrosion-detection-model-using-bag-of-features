{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries"
      ],
      "metadata": {
        "id": "Mok0Dr5KFXKb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYkvmYnl2Ydd"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage import feature\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "from keras.preprocessing import image\n",
        "import time\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.color import rgb2gray\n",
        "import pandas as pd\n",
        "from scipy.stats import entropy\n",
        "import seaborn as sns\n",
        "from skimage import data, color, exposure\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from skimage.feature import hog\n",
        "from scipy.stats import entropy, skew, kurtosis\n",
        "from scipy.stats import mstats\n",
        "from tqdm import tqdm  # For progress tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_BsT-DDe3Ru"
      },
      "outputs": [],
      "source": [
        "def get_images(training_mode, directory_path):\n",
        "    \"\"\"\n",
        "    Loads and processes images from a specified directory.\n",
        "\n",
        "    Args:\n",
        "        training_mode (bool): If True, the images will be shuffled randomly.\n",
        "        directory_path (str): Path to the directory containing the images.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of processed images in RGB format.\n",
        "    \"\"\"\n",
        "    images = []  # List to store processed images\n",
        "\n",
        "    # Retrieve and sort file names in the directory\n",
        "    file_list = sorted(os.listdir(directory_path))\n",
        "\n",
        "    for file_name in file_list:\n",
        "        # Construct the full path for each file\n",
        "        image_path = os.path.join(directory_path, file_name)\n",
        "\n",
        "        # Read the image using OpenCV\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        if image is not None:  # Ensure the image was loaded successfully\n",
        "            # Convert the image from BGR to RGB format\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            images.append(image_rgb)  # Add the processed image to the list\n",
        "\n",
        "    if training_mode:\n",
        "        # Shuffle images randomly if training mode is enabled\n",
        "        np.random.shuffle(images)\n",
        "\n",
        "    return images  # Return the list of processed images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89imX4E1fN-E"
      },
      "outputs": [],
      "source": [
        "path_images=\"path_to_the_train_images\"\n",
        "path_masks= \"path_to_the_train_masks\"\n",
        "images_train=get_images(train=False, path=path_images)\n",
        "masks_train=get_images(train=False, path=path_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGSN1Paf4UAc"
      },
      "outputs": [],
      "source": [
        "path_images_test=\"path_to_the_test_images\"\n",
        "path_mask_test= \"path_to_the_test_masks\"\n",
        "images_test=get_images(train=False, path=path_images_test)\n",
        "masks_test=get_images(train=False, path=path_mask_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZcGbAt5urKN"
      },
      "outputs": [],
      "source": [
        "images=images_train+images_test\n",
        "masks=masks_train+masks_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patch extraction"
      ],
      "metadata": {
        "id": "Nr8_uEKHF24c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Gle8OmBTfFk"
      },
      "outputs": [],
      "source": [
        "def get_patches_with_stride(image: np.ndarray, patch_size: tuple, stride: int) -> list[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Efficiently extracts image patches using strided operations.\n",
        "\n",
        "    Args:\n",
        "        image: Input image as a numpy array (H, W, C) or (H, W)\n",
        "        patch_size: Tuple (patch_height, patch_width)\n",
        "        stride: Step size between patch origins (same for vertical/horizontal)\n",
        "\n",
        "    Returns:\n",
        "        List of extracted patches as numpy arrays\n",
        "    \"\"\"\n",
        "    patch_h, patch_w = patch_size\n",
        "    img_h, img_w = image.shape[:2]\n",
        "\n",
        "    # Create sliding window view using numpy's optimized strided operations\n",
        "    patches = np.lib.stride_tricks.sliding_window_view(image, (patch_h, patch_w), axis=(0, 1))\n",
        "\n",
        "    # Select patches with specified stride\n",
        "    selected_patches = patches[::stride, ::stride]\n",
        "\n",
        "    # Reshape to list of patches and return\n",
        "    return [patch for patch in selected_patches.reshape(-1, patch_h, patch_w, *image.shape[2:])]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gaussian blur"
      ],
      "metadata": {
        "id": "rwD9hYJ9F-E8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSenRYTlxJoV"
      },
      "outputs": [],
      "source": [
        "def gaussian_blur(image, kernel_size, sigma):\n",
        "    \"\"\"\n",
        "    Applies a Gaussian blur to an image using OpenCV's GaussianBlur function.\n",
        "\n",
        "    Args:\n",
        "        image (numpy.ndarray): The input image to be blurred.\n",
        "        kernel_size (int): Size of the Gaussian kernel. Must be an odd number.\n",
        "        sigma (float): Standard deviation of the Gaussian kernel. Determines the intensity of the blur.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The blurred image.\n",
        "    \"\"\"\n",
        "    # Ensure kernel_size is odd, as required by the GaussianBlur function\n",
        "    if kernel_size % 2 == 0:\n",
        "        raise ValueError(\"Kernel size must be an odd number.\")\n",
        "\n",
        "    # Apply Gaussian blur to the input image\n",
        "    blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)\n",
        "\n",
        "    return blurred_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aok6YQJtWPml"
      },
      "source": [
        "## Color statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td3vbIpWynHC"
      },
      "outputs": [],
      "source": [
        "def calculate_channel_statistics(image_channel: np.ndarray) -> tuple[float, ...]:\n",
        "    \"\"\"\n",
        "    Calculates comprehensive statistical features for an image channel.\n",
        "\n",
        "    Args:\n",
        "        image_channel: 2D numpy array representing a single image channel\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing:\n",
        "        - mean: Average pixel intensity\n",
        "        - std_dev: Standard deviation of intensities\n",
        "        - entropy: Information entropy of pixel distribution\n",
        "        - kurt: Kurtosis (tailedness) of intensity distribution\n",
        "        - energy: Total energy of the signal\n",
        "        - skewness: Asymmetry of intensity distribution\n",
        "    \"\"\"\n",
        "    # Flatten the 2D array to 1D for statistical calculations\n",
        "    flat_channel = image_channel.ravel()\n",
        "\n",
        "    # Intensity distribution analysis (32-bin histogram from 0-255)\n",
        "    histogram_bins = np.arange(0, 256, 32)\n",
        "    hist, _ = np.histogram(flat_channel, bins=histogram_bins)\n",
        "\n",
        "    # Central tendency and dispersion\n",
        "    mean = np.mean(flat_channel)\n",
        "    std_dev = np.std(flat_channel)\n",
        "\n",
        "    # Information theory measures\n",
        "    hist_nonzero = hist[hist > 0]\n",
        "    entropy_val = entropy(hist_nonzero) if hist_nonzero.size > 0 else np.nan\n",
        "\n",
        "    # Shape characteristics\n",
        "    kurt = kurtosis(flat_channel)\n",
        "    skewness = skew(flat_channel)\n",
        "\n",
        "    # Signal energy calculation\n",
        "    energy = np.sum(flat_channel**2)\n",
        "\n",
        "    return (mean, std_dev, entropy_val, kurt, energy, skewness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO3Yix230t9k"
      },
      "outputs": [],
      "source": [
        "def extract_color_statistics_rgb(image_rgb: np.ndarray) -> tuple[tuple[float, ...], ...]:\n",
        "    \"\"\"\n",
        "    Extracts statistical features for each channel of an RGB image.\n",
        "\n",
        "    Args:\n",
        "        image_rgb: Input image in RGB format with shape (H, W, 3)\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing three feature tuples (red, green, blue channels)\n",
        "        Each channel tuple contains:\n",
        "        (mean, std_dev, entropy, kurtosis, energy, skewness)\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If input is not a 3-channel RGB image\n",
        "\n",
        "    \"\"\"\n",
        "    # Validate input dimensions\n",
        "    if image_rgb.ndim != 3 or image_rgb.shape[2] != 3:\n",
        "        raise ValueError(\"Input must be a 3-channel RGB image (H, W, 3)\")\n",
        "\n",
        "    # Extract color channels using numpy slicing\n",
        "    red_channel = image_rgb[..., 0]  # More efficient than [:, :, 0]\n",
        "    green_channel = image_rgb[..., 1]\n",
        "    blue_channel = image_rgb[..., 2]\n",
        "\n",
        "    # Calculate features for each channel\n",
        "    return (\n",
        "        calculate_channel_statistics(red_channel),\n",
        "        calculate_channel_statistics(green_channel),\n",
        "        calculate_channel_statistics(blue_channel)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0R4vdE81E8e"
      },
      "outputs": [],
      "source": [
        "def extract_color_statistics_hsv(image_rgb: np.ndarray) -> tuple[tuple[float, ...], ...]:\n",
        "    \"\"\"\n",
        "    Extracts statistical features for each channel of an HSV image.\n",
        "\n",
        "    Args:\n",
        "        image_rgb: Input image in RGB format with shape (H, W, 3)\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing three feature tuples (Hue, Saturation, Value)\n",
        "        Each channel tuple contains:\n",
        "        (mean, std_dev, entropy, kurtosis, energy, skewness)\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If input is not a 3-channel RGB image\n",
        "\n",
        "\n",
        "    Notes:\n",
        "        - Hue range: 0-179 (OpenCV's HSV representation)\n",
        "        - Saturation/Value range: 0-255\n",
        "        - Requires calculate_channel_statistics() implementation\n",
        "    \"\"\"\n",
        "    # Validate input dimensions\n",
        "    if image_rgb.ndim != 3 or image_rgb.shape[2] != 3:\n",
        "        raise ValueError(\"Input must be a 3-channel RGB image (H, W, 3)\")\n",
        "\n",
        "    # Convert to HSV color space (OpenCV expects BGR->HSV, ensure correct input)\n",
        "    hsv_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Extract channels using efficient numpy slicing\n",
        "    return (\n",
        "        calculate_channel_statistics(hsv_image[..., 0]),  # Hue\n",
        "        calculate_channel_statistics(hsv_image[..., 1]),  # Saturation\n",
        "        calculate_channel_statistics(hsv_image[..., 2])   # Value\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features algorithms"
      ],
      "metadata": {
        "id": "-1kA4FpHPRSE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1rEX-KHWb5I"
      },
      "source": [
        "### HOG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URFWushGbX2l"
      },
      "outputs": [],
      "source": [
        "def compute_hog_histogram(features: np.ndarray, bin_width: float = 0.1) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes a normalized histogram of HOG feature values.\n",
        "\n",
        "    Args:\n",
        "        features: HOG feature vector from skimage.feature.hog\n",
        "        bin_width: Width of histogram bins (0-1 range)\n",
        "\n",
        "    Returns:\n",
        "        Normalized histogram of HOG features with specified binning.\n",
        "    \"\"\"\n",
        "    # Create bins covering full [0, 1] range with specified width\n",
        "    bin_edges = np.arange(0, 1.0 + bin_width, bin_width)\n",
        "\n",
        "    # Compute histogram and normalize\n",
        "    hist, _ = np.histogram(features, bins=bin_edges)\n",
        "    return hist / hist.sum()  # Return probability distribution\n",
        "\n",
        "def extract_hog_features(\n",
        "    image: np.ndarray,\n",
        "    orientations: int = 9,\n",
        "    pixels_per_cell: tuple[int, int] = (8, 8),\n",
        "    cells_per_block: tuple[int, int] = (2, 2),\n",
        "    **hog_kwargs\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Extracts HOG features without resizing images smaller than 16x16.\n",
        "\n",
        "    Args:\n",
        "        image: Input image (grayscale or RGB).\n",
        "        orientations: Number of gradient orientation bins.\n",
        "        pixels_per_cell: Cell size in pixels.\n",
        "        cells_per_block: Block size in cells.\n",
        "        **hog_kwargs: Additional arguments for skimage.feature.hog.\n",
        "\n",
        "    Returns:\n",
        "        Normalized HOG feature histogram.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the image dimensions are smaller than 16x16.\n",
        "    \"\"\"\n",
        "    # Validate input dimensions\n",
        "    if image.shape[0] < 16 or image.shape[1] < 16:\n",
        "        raise ValueError(\"Image dimensions must be at least 16x16 pixels.\")\n",
        "\n",
        "    # Extract HOG features\n",
        "    try:\n",
        "        features = hog(\n",
        "            image,\n",
        "            orientations=orientations,\n",
        "            pixels_per_cell=pixels_per_cell,\n",
        "            cells_per_block=cells_per_block,\n",
        "            block_norm='L2-Hys',\n",
        "            channel_axis=-1 if image.ndim == 3 else None,\n",
        "            **hog_kwargs\n",
        "        )\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"HOG feature extraction failed: {str(e)}\") from e\n",
        "\n",
        "    return compute_hog_histogram(features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEKkQz9UWfZU"
      },
      "source": [
        "### LBP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssHF__p1jMAZ"
      },
      "outputs": [],
      "source": [
        "def lbp_features_color(img: np.ndarray, radius: int = 1, sampling_pixels: int = 8) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes Local Binary Pattern (LBP) features for a color image.\n",
        "\n",
        "    Args:\n",
        "        img: Input image in BGR/RGB format (3 channels).\n",
        "        radius: Radius of the LBP pattern (default=1).\n",
        "        sampling_pixels: Number of sampling points in the circular LBP pattern (default=8).\n",
        "\n",
        "    Returns:\n",
        "        A concatenated feature vector of LBP histograms for the 3 color channels.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the input image is empty or does not have 3 color channels.\n",
        "    \"\"\"\n",
        "\n",
        "    # Input validation\n",
        "    if img.size == 0:\n",
        "        raise ValueError(\"The input image is empty.\")\n",
        "    if len(img.shape) != 3 or img.shape[2] != 3:\n",
        "        raise ValueError(\"The image must have exactly 3 color channels.\")\n",
        "\n",
        "    # LBP configuration\n",
        "    METHOD = \"uniform\"\n",
        "    BINS = sampling_pixels + 2  # Bin for non-uniform patterns\n",
        "\n",
        "    # Process each color channel separately\n",
        "    histograms = []\n",
        "    for channel_index in range(3):\n",
        "        # Extract the channel and convert it to the appropriate type\n",
        "        channel = img[:, :, channel_index].astype(np.uint8)\n",
        "\n",
        "        # Compute the LBP pattern\n",
        "        lbp = feature.local_binary_pattern(\n",
        "            channel,\n",
        "            P=sampling_pixels,\n",
        "            R=radius,\n",
        "            method=METHOD\n",
        "        )\n",
        "\n",
        "        # Compute normalized histogram\n",
        "        hist, _ = np.histogram(\n",
        "            lbp.ravel(),\n",
        "            bins=np.arange(0, BINS + 1),\n",
        "            density=True  # Automatic normalization\n",
        "        )\n",
        "\n",
        "        histograms.append(hist)\n",
        "\n",
        "    # Concatenate histograms and ensure float32 type\n",
        "    return np.concatenate(histograms).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErYTfYvJWkF6"
      },
      "source": [
        "### GLCM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64DhQI2Vl52e"
      },
      "outputs": [],
      "source": [
        "def extract_glcm_features(image: np.ndarray,\n",
        "                         distances: list = [1],\n",
        "                         angles: list = [0, np.pi/4, np.pi/2, 3*np.pi/4]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Extracts texture features using Gray-Level Co-occurrence Matrix (GLCM) from a grayscale image.\n",
        "\n",
        "    Args:\n",
        "        image: Input RGB image (will be converted to grayscale)\n",
        "        distances: List of pixel distances for co-occurrence (default: [1])\n",
        "        angles: List of angles in radians (default: [0째, 45째, 90째, 135째])\n",
        "\n",
        "    Returns:\n",
        "        Concatenated feature vector containing:\n",
        "        [contrast, dissimilarity, homogeneity, energy, correlation]\n",
        "\n",
        "    Raises:\n",
        "        ValueError: For invalid image input\n",
        "    \"\"\"\n",
        "\n",
        "    # Input validation\n",
        "    if not isinstance(image, np.ndarray) or image.size == 0:\n",
        "        raise ValueError(\"Input must be a non-empty numpy array\")\n",
        "    if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "        raise ValueError(\"Input must be a 3-channel RGB image\")\n",
        "\n",
        "    # Convert to grayscale using OpenCV for better performance\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Normalize to 0-255 range if needed\n",
        "    if gray_image.dtype != np.uint8:\n",
        "        gray_image = (255 * (gray_image - gray_image.min()) /\n",
        "                     (gray_image.max() - gray_image.min() + 1e-6)).astype(np.uint8)\n",
        "\n",
        "    # Calculate GLCM matrix\n",
        "    glcm = graycomatrix(gray_image,\n",
        "                       distances=distances,\n",
        "                       angles=angles,\n",
        "                       symmetric=True,\n",
        "                       normed=True)\n",
        "\n",
        "    # Extract texture properties\n",
        "    features = []\n",
        "    for prop in ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']:\n",
        "        feature_values = graycoprops(glcm, prop)\n",
        "        features.append(feature_values.mean())  # Average across distances/angles\n",
        "\n",
        "    return np.array(features, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label"
      ],
      "metadata": {
        "id": "iJ2Nfjg2G5_M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sVnZxedEFzS"
      },
      "outputs": [],
      "source": [
        "class CorrosionLevel(Enum):\n",
        "    NONE = 'no_corrosion'\n",
        "    MILD = 'mild_corrosion'\n",
        "    MODERATE = 'moderate_corrosion'\n",
        "    SEVERE = 'severe_corrosion'\n",
        "\n",
        "def classify_corrosion_binary(region: np.ndarray) -> str:\n",
        "    \"\"\"\n",
        "    Classifies image region into corrosion (white) or no corrosion (black) using optimized vector operations.\n",
        "\n",
        "    Args:\n",
        "        region: Input image region (3-channel RGB array)\n",
        "\n",
        "    Returns:\n",
        "        Classification result ('corrosion' or 'no_corrosion')\n",
        "\n",
        "    \"\"\"\n",
        "    # Validate input\n",
        "    if not isinstance(region, np.ndarray) or region.size == 0:\n",
        "        raise ValueError(\"Invalid input region\")\n",
        "\n",
        "    # Reshape and vectorize operations\n",
        "    pixels = region.reshape(-1, 3)\n",
        "\n",
        "    # Count non-black pixels (corrosion)\n",
        "    corrosion_count = np.any(pixels != [0, 0, 0], axis=1).sum()\n",
        "    total_pixels = pixels.shape[0]\n",
        "\n",
        "    return 'corrosion' if corrosion_count / total_pixels > 0.5 else 'no_corrosion'\n",
        "\n",
        "def classify_corrosion_multiclass(region: np.ndarray) -> Tuple[CorrosionLevel, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Classifies corrosion severity using color-coded pixels with vectorized operations.\n",
        "\n",
        "    Args:\n",
        "        region: Input image region (3-channel RGB array)\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing:\n",
        "        - CorrosionLevel enum\n",
        "        - Normalized color distribution array\n",
        "    \"\"\"\n",
        "    # Validate input\n",
        "    if not isinstance(region, np.ndarray) or region.size == 0:\n",
        "        raise ValueError(\"Invalid input region\")\n",
        "\n",
        "    # Define color thresholds (BGR format - adjust)\n",
        "    COLOR_THRESHOLDS = {\n",
        "        CorrosionLevel.NONE: ([0, 0, 0], 10),       # Black\n",
        "        CorrosionLevel.MILD: ([0, 0, 200], 60),     # Red\n",
        "        CorrosionLevel.MODERATE: ([0, 200, 0], 60), # Green\n",
        "        CorrosionLevel.SEVERE: ([0, 200, 200], 60)  # Yellow\n",
        "    }\n",
        "\n",
        "    pixels = region.reshape(-1, 3)\n",
        "    counts = np.zeros(len(COLOR_THRESHOLDS), dtype=int)\n",
        "\n",
        "    # Vectorized color matching with tolerance\n",
        "    for idx, (level, (color, tolerance)) in enumerate(COLOR_THRESHOLDS.items()):\n",
        "        lower_bound = np.array(color) - tolerance\n",
        "        upper_bound = np.array(color) + tolerance\n",
        "        counts[idx] = np.sum(np.all((pixels >= lower_bound) & (pixels <= upper_bound), axis=1))\n",
        "\n",
        "    # Get distribution and classification\n",
        "    distribution = counts / counts.sum()\n",
        "    max_idx = np.argmax(counts)\n",
        "\n",
        "    return list(COLOR_THRESHOLDS.keys())[max_idx], distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZH-vhDobvvi"
      },
      "source": [
        "## Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DataFrame with proper columns\n",
        "columns= ['ID',\n",
        "    'red_mean', 'red_std', 'red_entropy','red_kurtosis', 'red_energy', 'red_skewness',\n",
        "    'green_mean', 'green_std', 'green_entropy','green_kurtosis', 'green_energy', 'green_skewness',\n",
        "    'blue_mean', 'blue_std', 'blue_entropy','blue_kurtosis', 'blue_energy', 'blue_skewness',\n",
        "    'hue_mean', 'hue_std', 'hue_entropy','hue_kurtosis', 'hue_energy', 'hue_skewness',\n",
        "    'saturation_mean', 'saturation_std', 'saturation_entropy','saturation_kurtosis', 'saturation_energy', 'saturation_skewness',\n",
        "    'value_mean', 'value_std', 'value_entropy','value_kurtosis', 'value_energy', 'value_skewness',\n",
        "    'glcm_contrast_0', 'glcm_dissimilarity_0', 'glcm_homogeneity_0', 'glcm_energy_0', 'glcm_correlation_0', 'glcm_ASM_0',\n",
        "    'glcm_contrast_1', 'glcm_dissimilarity_1', 'glcm_homogeneity_1', 'glcm_energy_1', 'glcm_correlation_1', 'glcm_ASM_1',\n",
        "    'glcm_contrast_2', 'glcm_dissimilarity_2', 'glcm_homogeneity_2', 'glcm_energy_2', 'glcm_correlation_2', 'glcm_ASM_2',\n",
        "    'glcm_contrast_3', 'glcm_dissimilarity_3', 'glcm_homogeneity_3', 'glcm_energy_3', 'glcm_correlation_3', 'glcm_ASM_3',\n",
        "    'hog_histogram_0', 'hog_histogram_0.1', 'hog_histogram_0.2', 'hog_histogram_0.3', 'hog_histogram_0.4', 'hog_histogram_0.5', 'hog_histogram_0.6', 'hog_histogram_0.7', 'hog_histogram_0.8',\n",
        "    'lbp_features_1', 'lbp_features_2', 'lbp_features_3', 'lbp_features_4','lbp_features_5','lbp_features_6','lbp_features_7','lbp_features_8','lbp_features_9','lbp_features_10',\n",
        "    'lbp_features_11', 'lbp_features_12', 'lbp_features_13', 'lbp_features_14', 'lbp_features_15', 'lbp_features_16', 'lbp_features_17', 'lbp_features_18', 'lbp_features_19', 'lbp_features_20',\n",
        "    'lbp_features_21', 'lbp_features_22', 'lbp_features_23', 'lbp_features_24', 'lbp_features_25', 'lbp_features_26', 'lbp_features_27', 'lbp_features_28', 'lbp_features_29', 'lbp_features_30',\n",
        "    'label_binary', 'label_multi', 'n_image'\n",
        "                          ]\n",
        "data = pd.DataFrame(columns=columns)\n",
        "\n",
        "# Configuration parameters\n",
        "GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "DISTANCES = [1]\n",
        "PATCH_SIZE = (32, 32)\n",
        "STRIDE = 4\n",
        "GAUSSIAN_KERNEL = 5\n",
        "GAUSSIAN_SIGMA = 1\n",
        "\n",
        "def process_image_pairs(images, masks):\n",
        "    \"\"\"Main processing function for image pairs\"\"\"\n",
        "    feature_rows = []\n",
        "\n",
        "    for img_idx, (image, mask) in enumerate(zip(images, masks)):\n",
        "        # Preprocess image\n",
        "        blurred_img = gaussian_blur(image, kernel_size=GAUSSIAN_KERNEL, sigma=GAUSSIAN_SIGMA)\n",
        "\n",
        "        # Extract patches\n",
        "        img_patches = get_patches_with_stride(blurred_img, PATCH_SIZE, STRIDE)\n",
        "        mask_patches = get_patches_with_stride(mask, PATCH_SIZE, STRIDE)\n",
        "\n",
        "        for patch_idx, (roi, mask_roi) in enumerate(zip(img_patches, mask_patches)):\n",
        "            try:\n",
        "                # Feature extraction\n",
        "                features = extract_features(roi)\n",
        "                labels = get_labels(mask_roi)\n",
        "\n",
        "                # Create feature row\n",
        "                row = {\n",
        "                    **features,\n",
        "                    **labels,\n",
        "                    'ID': f\"{img_idx}_{patch_idx}\",\n",
        "                    'n_image': img_idx\n",
        "                }\n",
        "                feature_rows.append(row)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing patch {img_idx}_{patch_idx}: {str(e)}\")\n",
        "\n",
        "    return pd.DataFrame(feature_rows)\n",
        "\n",
        "def extract_features(roi):\n",
        "    \"\"\"Unified feature extraction function\"\"\"\n",
        "    features = {}\n",
        "\n",
        "    # Color features\n",
        "    rgb_stats = extract_color_statistics_rgb(roi)\n",
        "    hsv_stats = extract_color_statistics_hsv(roi)\n",
        "\n",
        "    # Add color features to dict\n",
        "    color_stats = {\n",
        "        'red': rgb_stats[0],\n",
        "        'green': rgb_stats[1],\n",
        "        'blue': rgb_stats[2],\n",
        "        'hue': hsv_stats[0],\n",
        "        'saturation': hsv_stats[1],\n",
        "        'value': hsv_stats[2]\n",
        "    }\n",
        "    for stat_name, stats in color_stats.items():\n",
        "        features.update({\n",
        "            f'{stat_name}_mean': stats[0],\n",
        "            f'{stat_name}_std': stats[1],\n",
        "            f'{stat_name}_entropy': stats[2],\n",
        "            f'{stat_name}_kurtosis': stats[3],\n",
        "            f'{stat_name}_energy': stats[4],\n",
        "            f'{stat_name}_skewness': stats[5]\n",
        "        })\n",
        "\n",
        "    # GLCM features\n",
        "    for angle_idx, angle in enumerate(GLCM_ANGLES):\n",
        "        glcm_features = extract_glcm_features(roi, DISTANCES, [angle])\n",
        "        features.update({\n",
        "            f'glcm_contrast_{angle_idx}': glcm_features[0],\n",
        "            f'glcm_dissimilarity_{angle_idx}': glcm_features[1],\n",
        "            f'glcm_homogeneity_{angle_idx}': glcm_features[2],\n",
        "            f'glcm_energy_{angle_idx}': glcm_features[3],\n",
        "            f'glcm_correlation_{angle_idx}': glcm_features[4],\n",
        "            f'glcm_ASM_{angle_idx}': glcm_features[5]\n",
        "        })\n",
        "\n",
        "    # HOG and LBP features\n",
        "    hog_features = features_hog(roi)\n",
        "    lbp_features = lbp_features_color(roi)\n",
        "\n",
        "    features.update({\n",
        "        **{f'hog_histogram_{i/10:.1f}': val for i, val in enumerate(hog_features)},\n",
        "        **{f'lbp_features_{i+1}': val for i, val in enumerate(lbp_features)}\n",
        "    })\n",
        "\n",
        "    return features\n",
        "\n",
        "def get_labels(mask_roi):\n",
        "    \"\"\"Get classification labels\"\"\"\n",
        "    return {\n",
        "        'label_binary': classify_corrosion_binary(mask_roi),\n",
        "        'label_multi': classify_corrosion_multiclass(mask_roi)\n",
        "    }\n",
        "\n",
        "# Main execution\n",
        "start_time = time.time()\n",
        "df = process_image_pairs(images_tot, masks_tot)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Processing completed in {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Generated {len(df)} samples\")\n",
        "df.to_csv('features_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "57c8onf_ONeh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}